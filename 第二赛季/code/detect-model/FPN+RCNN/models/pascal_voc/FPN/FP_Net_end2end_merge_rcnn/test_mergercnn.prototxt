
name: "ResNet-50"
input: "data"
input_shape {
  dim: 1
  dim: 3
  dim: 224
  dim: 224
}

input: "im_info"
input_shape {
  dim: 1
  dim: 3
}
layer {
	bottom: "data"
	top: "conv1"
	name: "conv1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 7
		pad: 3
		stride: 2
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "bn_conv1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "scale_conv1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "conv1_relu"
	type: "ReLU"
}

layer {
	bottom: "conv1"
	top: "pool1"
	name: "pool1"
	type: "Pooling"
	pooling_param {
		kernel_size: 3
		stride: 2
		pool: MAX
	}
}

layer {
	bottom: "pool1"
	top: "res2a_branch1"
	name: "res2a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch1"
	top: "res2a_branch1"
	name: "bn2a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch1"
	top: "res2a_branch1"
	name: "scale2a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "pool1"
	top: "res2a_branch2a"
	name: "res2a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2a"
	name: "bn2a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2a"
	name: "scale2a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2a"
	name: "res2a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2b"
	name: "res2a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2b"
	name: "bn2a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2b"
	name: "scale2a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2b"
	name: "res2a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2c"
	name: "res2a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2c"
	top: "res2a_branch2c"
	name: "bn2a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch2c"
	top: "res2a_branch2c"
	name: "scale2a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2a_branch1"
	bottom: "res2a_branch2c"
	top: "res2a"
	name: "res2a"
	type: "Eltwise"
}

layer {
	bottom: "res2a"
	top: "res2a"
	name: "res2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2a"
	top: "res2b_branch2a"
	name: "res2b_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2a"
	name: "bn2b_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2a"
	name: "scale2b_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2a"
	name: "res2b_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2b"
	name: "res2b_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2b"
	name: "bn2b_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2b"
	name: "scale2b_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2b"
	name: "res2b_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2c"
	name: "res2b_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2c"
	top: "res2b_branch2c"
	name: "bn2b_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2b_branch2c"
	top: "res2b_branch2c"
	name: "scale2b_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2a"
	bottom: "res2b_branch2c"
	top: "res2b"
	name: "res2b"
	type: "Eltwise"
}

layer {
	bottom: "res2b"
	top: "res2b"
	name: "res2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2b"
	top: "res2c_branch2a"
	name: "res2c_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2a"
	name: "bn2c_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2a"
	name: "scale2c_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2a"
	name: "res2c_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2b"
	name: "res2c_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2b"
	name: "bn2c_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2b"
	name: "scale2c_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2b"
	name: "res2c_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2c"
	name: "res2c_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2c"
	top: "res2c_branch2c"
	name: "bn2c_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2c_branch2c"
	top: "res2c_branch2c"
	name: "scale2c_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2b"
	bottom: "res2c_branch2c"
	top: "res2c"
	name: "res2c"
	type: "Eltwise"
}

layer {
	bottom: "res2c"
	top: "res2c"
	name: "res2c_relu"
	type: "ReLU"
}

layer {
	bottom: "res2c"
	top: "res3a_branch1"
	name: "res3a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch1"
	top: "res3a_branch1"
	name: "bn3a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch1"
	top: "res3a_branch1"
	name: "scale3a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2c"
	top: "res3a_branch2a"
	name: "res3a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2a"
	name: "bn3a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2a"
	name: "scale3a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2a"
	name: "res3a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2b"
	name: "res3a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2b"
	name: "bn3a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2b"
	name: "scale3a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2b"
	name: "res3a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2c"
	name: "res3a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2c"
	top: "res3a_branch2c"
	name: "bn3a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch2c"
	top: "res3a_branch2c"
	name: "scale3a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3a_branch1"
	bottom: "res3a_branch2c"
	top: "res3a"
	name: "res3a"
	type: "Eltwise"
}

layer {
	bottom: "res3a"
	top: "res3a"
	name: "res3a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3a"
	top: "res3b_branch2a"
	name: "res3b_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b_branch2a"
	top: "res3b_branch2a"
	name: "bn3b_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b_branch2a"
	top: "res3b_branch2a"
	name: "scale3b_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3b_branch2a"
	top: "res3b_branch2a"
	name: "res3b_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b_branch2a"
	top: "res3b_branch2b"
	name: "res3b_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b_branch2b"
	top: "res3b_branch2b"
	name: "bn3b_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b_branch2b"
	top: "res3b_branch2b"
	name: "scale3b_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3b_branch2b"
	top: "res3b_branch2b"
	name: "res3b_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b_branch2b"
	top: "res3b_branch2c"
	name: "res3b_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b_branch2c"
	top: "res3b_branch2c"
	name: "bn3b_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b_branch2c"
	top: "res3b_branch2c"
	name: "scale3b_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3a"
	bottom: "res3b_branch2c"
	top: "res3b"
	name: "res3b"
	type: "Eltwise"
}

layer {
	bottom: "res3b"
	top: "res3b"
	name: "res3b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b"
	top: "res3c_branch2a"
	name: "res3c_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3c_branch2a"
	top: "res3c_branch2a"
	name: "bn3c_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3c_branch2a"
	top: "res3c_branch2a"
	name: "scale3c_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3c_branch2a"
	top: "res3c_branch2a"
	name: "res3c_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3c_branch2a"
	top: "res3c_branch2b"
	name: "res3c_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3c_branch2b"
	top: "res3c_branch2b"
	name: "bn3c_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3c_branch2b"
	top: "res3c_branch2b"
	name: "scale3c_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3c_branch2b"
	top: "res3c_branch2b"
	name: "res3c_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3c_branch2b"
	top: "res3c_branch2c"
	name: "res3c_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3c_branch2c"
	top: "res3c_branch2c"
	name: "bn3c_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3c_branch2c"
	top: "res3c_branch2c"
	name: "scale3c_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3b"
	bottom: "res3c_branch2c"
	top: "res3c"
	name: "res3c"
	type: "Eltwise"
}

layer {
	bottom: "res3c"
	top: "res3c"
	name: "res3c_relu"
	type: "ReLU"
}

layer {
	bottom: "res3c"
	top: "res3d_branch2a"
	name: "res3d_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3d_branch2a"
	top: "res3d_branch2a"
	name: "bn3d_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3d_branch2a"
	top: "res3d_branch2a"
	name: "scale3d_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3d_branch2a"
	top: "res3d_branch2a"
	name: "res3d_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3d_branch2a"
	top: "res3d_branch2b"
	name: "res3d_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3d_branch2b"
	top: "res3d_branch2b"
	name: "bn3d_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3d_branch2b"
	top: "res3d_branch2b"
	name: "scale3d_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3d_branch2b"
	top: "res3d_branch2b"
	name: "res3d_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3d_branch2b"
	top: "res3d_branch2c"
	name: "res3d_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3d_branch2c"
	top: "res3d_branch2c"
	name: "bn3d_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3d_branch2c"
	top: "res3d_branch2c"
	name: "scale3d_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3c"
	bottom: "res3d_branch2c"
	top: "res3d"
	name: "res3d"
	type: "Eltwise"
}

layer {
	bottom: "res3d"
	top: "res3d"
	name: "res3d_relu"
	type: "ReLU"
}

layer {
	bottom: "res3d"
	top: "res4a_branch1"
	name: "res4a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch1"
	top: "res4a_branch1"
	name: "bn4a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch1"
	top: "res4a_branch1"
	name: "scale4a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3d"
	top: "res4a_branch2a"
	name: "res4a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2a"
	name: "bn4a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2a"
	name: "scale4a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2a"
	name: "res4a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2b"
	name: "res4a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2b"
	name: "bn4a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2b"
	name: "scale4a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2b"
	name: "res4a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2c"
	name: "res4a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2c"
	top: "res4a_branch2c"
	name: "bn4a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch2c"
	top: "res4a_branch2c"
	name: "scale4a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4a_branch1"
	bottom: "res4a_branch2c"
	top: "res4a"
	name: "res4a"
	type: "Eltwise"
}

layer {
	bottom: "res4a"
	top: "res4a"
	name: "res4a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4a"
	top: "res4b_branch2a"
	name: "res4b_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b_branch2a"
	top: "res4b_branch2a"
	name: "bn4b_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b_branch2a"
	top: "res4b_branch2a"
	name: "scale4b_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b_branch2a"
	top: "res4b_branch2a"
	name: "res4b_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b_branch2a"
	top: "res4b_branch2b"
	name: "res4b_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b_branch2b"
	top: "res4b_branch2b"
	name: "bn4b_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b_branch2b"
	top: "res4b_branch2b"
	name: "scale4b_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b_branch2b"
	top: "res4b_branch2b"
	name: "res4b_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b_branch2b"
	top: "res4b_branch2c"
	name: "res4b_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b_branch2c"
	top: "res4b_branch2c"
	name: "bn4b_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b_branch2c"
	top: "res4b_branch2c"
	name: "scale4b_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4a"
	bottom: "res4b_branch2c"
	top: "res4b"
	name: "res4b"
	type: "Eltwise"
}

layer {
	bottom: "res4b"
	top: "res4b"
	name: "res4b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b"
	top: "res4c_branch2a"
	name: "res4c_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4c_branch2a"
	top: "res4c_branch2a"
	name: "bn4c_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4c_branch2a"
	top: "res4c_branch2a"
	name: "scale4c_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4c_branch2a"
	top: "res4c_branch2a"
	name: "res4c_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4c_branch2a"
	top: "res4c_branch2b"
	name: "res4c_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4c_branch2b"
	top: "res4c_branch2b"
	name: "bn4c_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4c_branch2b"
	top: "res4c_branch2b"
	name: "scale4c_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4c_branch2b"
	top: "res4c_branch2b"
	name: "res4c_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4c_branch2b"
	top: "res4c_branch2c"
	name: "res4c_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4c_branch2c"
	top: "res4c_branch2c"
	name: "bn4c_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4c_branch2c"
	top: "res4c_branch2c"
	name: "scale4c_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b"
	bottom: "res4c_branch2c"
	top: "res4c"
	name: "res4c"
	type: "Eltwise"
}

layer {
	bottom: "res4c"
	top: "res4c"
	name: "res4c_relu"
	type: "ReLU"
}

layer {
	bottom: "res4c"
	top: "res4d_branch2a"
	name: "res4d_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4d_branch2a"
	top: "res4d_branch2a"
	name: "bn4d_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4d_branch2a"
	top: "res4d_branch2a"
	name: "scale4d_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4d_branch2a"
	top: "res4d_branch2a"
	name: "res4d_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4d_branch2a"
	top: "res4d_branch2b"
	name: "res4d_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4d_branch2b"
	top: "res4d_branch2b"
	name: "bn4d_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4d_branch2b"
	top: "res4d_branch2b"
	name: "scale4d_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4d_branch2b"
	top: "res4d_branch2b"
	name: "res4d_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4d_branch2b"
	top: "res4d_branch2c"
	name: "res4d_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4d_branch2c"
	top: "res4d_branch2c"
	name: "bn4d_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4d_branch2c"
	top: "res4d_branch2c"
	name: "scale4d_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4c"
	bottom: "res4d_branch2c"
	top: "res4d"
	name: "res4d"
	type: "Eltwise"
}

layer {
	bottom: "res4d"
	top: "res4d"
	name: "res4d_relu"
	type: "ReLU"
}

layer {
	bottom: "res4d"
	top: "res4e_branch2a"
	name: "res4e_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4e_branch2a"
	top: "res4e_branch2a"
	name: "bn4e_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4e_branch2a"
	top: "res4e_branch2a"
	name: "scale4e_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4e_branch2a"
	top: "res4e_branch2a"
	name: "res4e_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4e_branch2a"
	top: "res4e_branch2b"
	name: "res4e_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4e_branch2b"
	top: "res4e_branch2b"
	name: "bn4e_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4e_branch2b"
	top: "res4e_branch2b"
	name: "scale4e_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4e_branch2b"
	top: "res4e_branch2b"
	name: "res4e_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4e_branch2b"
	top: "res4e_branch2c"
	name: "res4e_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4e_branch2c"
	top: "res4e_branch2c"
	name: "bn4e_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4e_branch2c"
	top: "res4e_branch2c"
	name: "scale4e_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4d"
	bottom: "res4e_branch2c"
	top: "res4e"
	name: "res4e"
	type: "Eltwise"
}

layer {
	bottom: "res4e"
	top: "res4e"
	name: "res4e_relu"
	type: "ReLU"
}

layer {
	bottom: "res4e"
	top: "res4f_branch2a"
	name: "res4f_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4f_branch2a"
	top: "res4f_branch2a"
	name: "bn4f_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4f_branch2a"
	top: "res4f_branch2a"
	name: "scale4f_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4f_branch2a"
	top: "res4f_branch2a"
	name: "res4f_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4f_branch2a"
	top: "res4f_branch2b"
	name: "res4f_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4f_branch2b"
	top: "res4f_branch2b"
	name: "bn4f_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4f_branch2b"
	top: "res4f_branch2b"
	name: "scale4f_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4f_branch2b"
	top: "res4f_branch2b"
	name: "res4f_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4f_branch2b"
	top: "res4f_branch2c"
	name: "res4f_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4f_branch2c"
	top: "res4f_branch2c"
	name: "bn4f_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4f_branch2c"
	top: "res4f_branch2c"
	name: "scale4f_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4e"
	bottom: "res4f_branch2c"
	top: "res4f"
	name: "res4f"
	type: "Eltwise"
}

layer {
	bottom: "res4f"
	top: "res4f"
	name: "res4f_relu"
	type: "ReLU"
}

layer {
	bottom: "res4f"
	top: "res5a_branch1"
	name: "res5a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch1"
	top: "res5a_branch1"
	name: "bn5a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch1"
	top: "res5a_branch1"
	name: "scale5a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4f"
	top: "res5a_branch2a"
	name: "res5a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2a"
	name: "bn5a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2a"
	name: "scale5a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2a"
	name: "res5a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2b"
	name: "res5a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2b"
	name: "bn5a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2b"
	name: "scale5a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2b"
	name: "res5a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2c"
	name: "res5a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2c"
	top: "res5a_branch2c"
	name: "bn5a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2c"
	top: "res5a_branch2c"
	name: "scale5a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch1"
	bottom: "res5a_branch2c"
	top: "res5a"
	name: "res5a"
	type: "Eltwise"
}

layer {
	bottom: "res5a"
	top: "res5a"
	name: "res5a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5a"
	top: "res5b_branch2a"
	name: "res5b_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2a"
	name: "bn5b_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2a"
	name: "scale5b_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2a"
	name: "res5b_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2b"
	name: "res5b_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2b"
	name: "bn5b_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2b"
	name: "scale5b_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2b"
	name: "res5b_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2c"
	name: "res5b_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2c"
	top: "res5b_branch2c"
	name: "bn5b_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2c"
	top: "res5b_branch2c"
	name: "scale5b_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a"
	bottom: "res5b_branch2c"
	top: "res5b"
	name: "res5b"
	type: "Eltwise"
}

layer {
	bottom: "res5b"
	top: "res5b"
	name: "res5b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5b"
	top: "res5c_branch2a"
	name: "res5c_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2a"
	name: "bn5c_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2a"
	name: "scale5c_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2a"
	name: "res5c_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2b"
	name: "res5c_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2b"
	name: "bn5c_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2b"
	name: "scale5c_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2b"
	name: "res5c_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2c"
	name: "res5c_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2c"
	top: "res5c_branch2c"
	name: "bn5c_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2c"
	top: "res5c_branch2c"
	name: "scale5c_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b"
	bottom: "res5c_branch2c"
	top: "res5c"
	name: "res5c"
	type: "Eltwise"
}

layer {
	bottom: "res5c"
	top: "res5c"
	name: "res5c_relu"
	type: "ReLU"
}
layer {
	bottom: "res5c"
	top: "res6"
	name: "pool_res6"
	type: "Pooling"
	pooling_param {
		kernel_size: 3
		stride: 2
		pool: MAX
	}
}
####lateral

layer {
	bottom: "res6"
	top: "p6"
	name: "p6"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
        
	}
}

layer {
	bottom: "res5c"
	top: "p5"
	name: "p5"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
        
	}
}

layer {
    name: "upP5"
	type: "Deconvolution"
    bottom: "p5" 
	top: "upP5"
    convolution_param {
    kernel_h : 4
    kernel_w : 4
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    num_output: 256
    group: 256
    bias_term: false
     weight_filler {
      type: "bilinear"
    }
  }
  param { lr_mult: 0 decay_mult: 0 } 
}

layer {
	bottom: "res4f"
	top: "c4"
	name: "newC4"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0.0 }
        
	}
}

layer {
    name: "p4"
    type: "Eltwise"
    bottom: "c4"
    bottom: "upP5"
    top: "p4"
    eltwise_param {
        operation: SUM
    }
}


layer {
	bottom: "p4"
	top: "p4_lateral"
	name: "p4_lateral"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0.0 }
        
	}
}
layer {
    name: "upP4"
	type: "Deconvolution"
    bottom: "p4_lateral" 
	top: "upP4"
    convolution_param {
    kernel_h : 4
    kernel_w : 4
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    num_output: 256
    group: 256
    bias_term: false
     weight_filler {
      type: "bilinear"
    }
  }
  param { lr_mult: 0 decay_mult: 0 } 
}


layer {
	bottom: "res3d"
	top: "c3"
	name: "newC3"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0.0 }
        
	}
}
layer {
    name: "p3"
    type: "Eltwise"
    bottom: "c3"
    bottom: "upP4"
    top: "p3"
    eltwise_param {
        operation: SUM
    }
}


layer {
	bottom: "p3"
	top: "p3_lateral"
	name: "p3_lateral"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0.0 }
        
	}
}

layer {
	bottom: "res2c"
	top: "c2"
	name: "newC2"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0.0 }
        
	}
}
layer {
    name: "upP2"
	type: "Deconvolution"
    bottom: "p3_lateral" 
	top: "upP2"
    convolution_param {
    kernel_h : 4
    kernel_w : 4
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    num_output: 256
    group: 256
    bias_term: false
     weight_filler {
      type: "bilinear"
    }
  }
  param { lr_mult: 0 decay_mult: 0 } 
}
layer {
    name: "p2"
    type: "Eltwise"
    bottom: "c2"
    bottom: "upP2"
    top: "p2"
    eltwise_param {
        operation: SUM
    }
}




####

#========= RPN/p2 ============

layer {
  name: "rpn_conv/3x3/p2"
  type: "Convolution"
  bottom: "p2"
  top: "rpn/output/p2"
  param { lr_mult: 1.0
  		  name: "rpn_conv_3x3_w"
          }
  param { lr_mult: 2.0
  		  name: "rpn_conv_3x3_b"
          }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu/3x3/p2"
  type: "ReLU"
  bottom: "rpn/output/p2"
  top: "rpn/output/p2"
}

layer {
  name: "rpn_cls_score/p2"
  type: "Convolution"
  bottom: "rpn/output/p2"
  top: "rpn_cls_score/p2"
  param { lr_mult: 1.0
  		name: "rpn_cls_score_w" }
  param { lr_mult: 2.0
 		name: "rpn_cls_score_b"
        }
  convolution_param {
    num_output: 12   # 2(bg/fg) * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_bbox_pred/p2"
  type: "Convolution"
  bottom: "rpn/output/p2"
  top: "rpn_bbox_pred/p2"
  param { lr_mult: 1.0
  		name: "rpn_bbox_pred_w"
        }
  param { lr_mult: 2.0
  name: "rpn_bbox_pred_b"
  }
  convolution_param {
    num_output: 24   # 4 * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

######

layer {
   bottom: "rpn_cls_score/p2"
   top: "rpn_cls_score_reshape_/p2"
   name: "rpn_cls_score_reshape_/p2"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}







#####CLS out


layer {
  name: "fpn_out/p2"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape_/p2"
  top: "fpn_out/p2"
}

layer {
   bottom: "fpn_out/p2"
   top: "fpn_out_reshape/p2"
   name: "fpn_out_reshape/p2"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 12 dim: -1 dim: 0  } }
}


#========= RPN/p3 ============

layer {
  name: "rpn_conv/3x3/p3"
  type: "Convolution"
  bottom: "p3"
  top: "rpn/output/p3"
  param { lr_mult: 1.0
        name: "rpn_conv_3x3_w"
  }
  param { lr_mult: 2.0 
   name: "rpn_conv_3x3_b"
  }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu/3x3/p3"
  type: "ReLU"
  bottom: "rpn/output/p3"
  top: "rpn/output/p3"
}

layer {
  name: "rpn_cls_score/p3"
  type: "Convolution"
  bottom: "rpn/output/p3"
  top: "rpn_cls_score/p3"
  param { lr_mult: 1.0 
  name: "rpn_cls_score_w"
  }
  param { lr_mult: 2.0
    name: "rpn_cls_score_b"
    }
  convolution_param {
    num_output: 12   # 2(bg/fg) * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_bbox_pred/p3"
  type: "Convolution"
  bottom: "rpn/output/p3"
  top: "rpn_bbox_pred/p3"
  param { lr_mult: 1.0
  name:"rpn_bbox_pred_w"
  }
  param { lr_mult: 2.0
   name:"rpn_bbox_pred_b" 
  }
  convolution_param {
    num_output: 24   # 4 * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}

######

layer {
   bottom: "rpn_cls_score/p3"
   top: "rpn_cls_score_reshape_/p3"
   name: "rpn_cls_score_reshape_/p3"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}






#####CLS out


layer {
  name: "fpn_out/p3"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape_/p3"
  top: "fpn_out/p3"
}

layer {
   bottom: "fpn_out/p3"
   top: "fpn_out_reshape/p3"
   name: "fpn_out_reshape/p3"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 12 dim: -1 dim: 0  } }
}



#========= RPN/p4 ============

layer {
  name: "rpn_conv/3x3/p4"
  type: "Convolution"
  bottom: "p4"
  top: "rpn/output/p4"
  param { lr_mult: 1.0
  name: "rpn_conv_3x3_w"
  }
  param { lr_mult: 2.0 
    name: "rpn_conv_3x3_b"
  }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu/3x3/p4"
  type: "ReLU"
  bottom: "rpn/output/p4"
  top: "rpn/output/p4"
}

layer {
  name: "rpn_cls_score/p4"
  type: "Convolution"
  bottom: "rpn/output/p4"
  top: "rpn_cls_score/p4"
  param { lr_mult: 1.0 
  name:"rpn_cls_score_w"
  }
  param { lr_mult: 2.0
  name:"rpn_cls_score_b"
    }
  convolution_param {
    num_output: 12   # 2(bg/fg) * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_bbox_pred/p4"
  type: "Convolution"
  bottom: "rpn/output/p4"
  top: "rpn_bbox_pred/p4"
  param { lr_mult: 1.0
  name:"rpn_bbox_pred_w"
  }
  param { lr_mult: 2.0
    name:"rpn_bbox_pred_b"
  }
  convolution_param {
    num_output: 24   # 4 * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}

######

layer {
   bottom: "rpn_cls_score/p4"
   top: "rpn_cls_score_reshape_/p4"
   name: "rpn_cls_score_reshape_/p4"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}






#####CLS out


layer {
  name: "fpn_out/p4"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape_/p4"
  top: "fpn_out/p4"
}

layer {
   bottom: "fpn_out/p4"
   top: "fpn_out_reshape/p4"
   name: "fpn_out_reshape/p4"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 12 dim: -1 dim: 0  } }
}




#========= RPN/p5 ============

layer {
  name: "rpn_conv/3x3/p5"
  type: "Convolution"
  bottom: "p5"
  top: "rpn/output/p5"
  param { lr_mult: 1.0
  name:"rpn_conv_3x3_w"
  }
  param { lr_mult: 2.0
    name:"rpn_conv_3x3_b"
  }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu/3x3/p5"
  type: "ReLU"
  bottom: "rpn/output/p5"
  top: "rpn/output/p5"
}

layer {
  name: "rpn_cls_score/p5"
  type: "Convolution"
  bottom: "rpn/output/p5"
  top: "rpn_cls_score/p5"
  param { lr_mult: 1.0
  name:"rpn_cls_score_w"
  
  }
  param { lr_mult: 2.0
  name:"rpn_cls_score_b"
  }
  convolution_param {
    num_output: 12   # 2(bg/fg) * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_bbox_pred/p5"
  type: "Convolution"
  bottom: "rpn/output/p5"
  top: "rpn_bbox_pred/p5"
  param { lr_mult: 1.0 
  name:"rpn_bbox_pred_w"
  }
  param { lr_mult: 2.0
    name:"rpn_bbox_pred_b"
    }
  convolution_param {
    num_output: 24  # 4 * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

######

layer {
   bottom: "rpn_cls_score/p5"
   top: "rpn_cls_score_reshape_/p5"
   name: "rpn_cls_score_reshape_/p5"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}






#####CLS out


layer {
  name: "fpn_out/p5"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape_/p5"
  top: "fpn_out/p5"
}

layer {
   bottom: "fpn_out/p5"
   top: "fpn_out_reshape/p5"
   name: "fpn_out_reshape/p5"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 12 dim: -1 dim: 0  } }
}

#========= RPN/p6 ============

layer {
  name: "rpn_conv/3x3/p6"
  type: "Convolution"
  bottom: "p6"
  top: "rpn/output/p6"
  param { lr_mult: 1.0
  name:"rpn_conv_3x3_w"
  }
  param { lr_mult: 2.0
    name:"rpn_conv_3x3_b"
  }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu/3x3/p6"
  type: "ReLU"
  bottom: "rpn/output/p6"
  top: "rpn/output/p6"
}

layer {
  name: "rpn_cls_score/p6"
  type: "Convolution"
  bottom: "rpn/output/p6"
  top: "rpn_cls_score/p6"
  param { lr_mult: 1.0
  name:"rpn_cls_score_w"
  
  }
  param { lr_mult: 2.0
  name:"rpn_cls_score_b"
  }
  convolution_param {
    num_output: 12   # 2(bg/fg) * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_bbox_pred/p6"
  type: "Convolution"
  bottom: "rpn/output/p6"
  top: "rpn_bbox_pred/p6"
  param { lr_mult: 1.0 
  name:"rpn_bbox_pred_w"
  }
  param { lr_mult: 2.0
    name:"rpn_bbox_pred_b"
    }
  convolution_param {
    num_output: 24  # 4 * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}


######

layer {
   bottom: "rpn_cls_score/p6"
   top: "rpn_cls_score_reshape_/p6"
   name: "rpn_cls_score_reshape_/p6"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}







#####CLS out


layer {
  name: "fpn_out/p6"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape_/p6"
  top: "fpn_out/p6"
}

layer {
   bottom: "fpn_out/p6"
   top: "fpn_out_reshape/p6"
   name: "fpn_out_reshape/p6"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 12 dim: -1 dim: 0  } }
}

########rpn loss#####################










#========= RoI Proposal ============



 

layer {
  name: 'proposal'
  type: 'Python'
    bottom: 'im_info'
    bottom: 'rpn_bbox_pred/p2'
    bottom: 'rpn_bbox_pred/p3'
	bottom: 'rpn_bbox_pred/p4'
	bottom: 'rpn_bbox_pred/p5'
	bottom: 'rpn_bbox_pred/p6'
 	bottom: 'fpn_out_reshape/p2'
	bottom: 'fpn_out_reshape/p3'
	bottom: 'fpn_out_reshape/p4'
	bottom: 'fpn_out_reshape/p5'
	bottom: 'fpn_out_reshape/p6'
  top: 'rpn_rois'
  python_param {
    module: 'rpn.proposal_layer'
    layer: 'ProposalLayer'
    param_str: "'feat_stride': 4,8,16,32,64"

  }
}



#================rois process======================

layer {
  name: 'as_rois'
  type: 'Python'
  bottom: 'rpn_rois'
  top: 'rois'
  top: 'rois/h2'
  top: 'rois/h3'
  top: 'rois/h4'
  top: 'rois/h5'
  python_param {
    module: 'rpn.as_rois_mrcnn'
    layer: 'As_rois_MergeRcnnLayer'

  }
}

#========= RCNN ============

######POOLING=======
layer {
  name: "roi_pool/h2"
  type: "ROIPooling"
  bottom: "p2"
  bottom: "rois/h2"
  top: "roi_pool/h2"
  roi_pooling_param {
    pooled_w: 7
    pooled_h: 7
    spatial_scale: 0.25 # 1/4
  }
}


layer {
  name: "roi_pool/h3"
  type: "ROIPooling"
  bottom: "p3"
  bottom: "rois/h3"
  top: "roi_pool/h3"
  roi_pooling_param {
    pooled_w: 7
    pooled_h: 7
    spatial_scale: 0.125 # 1/8
  }
}
layer {
  name: "roi_pool/h4"
  type: "ROIPooling"
  bottom: "p4"
  bottom: "rois/h4"
  top: "roi_pool/h4"
  roi_pooling_param {
    pooled_w: 7
    pooled_h: 7
    spatial_scale: 0.0625 # 1/16
  }
}

layer {
  name: "roi_pool/h5"
  type: "ROIPooling"
  bottom: "p5"
  bottom: "rois/h5"
  top: "roi_pool/h5"
  roi_pooling_param {
    pooled_w: 7
    pooled_h: 7
    spatial_scale: 0.03125 # 1/32
  }
}


layer {
  name: "roi_pool_concat"
  type: "Concat"
  bottom: "roi_pool/h2"
  bottom: "roi_pool/h3"
  bottom: "roi_pool/h4"
  bottom: "roi_pool/h5"
  top: "roi_pool"
  concat_param {
    axis: 0
  }
}

#h2
layer {
  name: "rcnn_fc6"
  type: "InnerProduct"
  bottom: "roi_pool"
  top: "rcnn_fc6"
  param {
    lr_mult: 1
    name: "rcnn_fc6_w"
  }
  param {
    lr_mult: 2
    name: "rcnn_fc6_b"
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "rcnn_fc6"
  top: "rcnn_fc6"
}

layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "rcnn_fc6"
  top: "fc7"
  param {
    lr_mult: 1
    name:"fc7_w"
  }
  param {
    lr_mult: 2
    name: "fc7_b"
  }
  inner_product_param {
    num_output: 1024
    weight_filler { 
    type: "xavier"  
    }  
    bias_filler {  
      type: "constant"  
    } 
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}

layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
    name:"cls_score_w"
  }
  param {
    lr_mult: 2
    name:"cls_score_b"
  }
  inner_product_param {
    num_output: 21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
    name:"bbox_pred_w"
  }
  param {
    lr_mult: 2
    name:"bbox_pred_b"
  }
  inner_product_param {
    num_output: 44
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "cls_prob"
  type: "Softmax"
  bottom: "cls_score"
  top: "cls_prob"
}






